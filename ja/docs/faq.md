# FAQ

## Q. 動作が安定しない

1. 予測データを混合する
    実世界のノイズに対し安定的な動作を生成するために、時刻$t$のセンサ情報に、前時刻$t-1$でもRNNの予測値を一定の割合で混合した値をRNNに入力する。
    本処理はローパスフィルタと同等であり、ロボットのセンサ値にノイズが乗っても、 前時刻の予測値を補助的に利用することで、安定した動作指令の予測が可能である。
    なお混合係数(`input_param`)が小さ過ぎると、実世界のセンサ情報に基づいて動作を修正することが困難になるため、位置変化に対するロバスト性が低下することに注意されたい。
    仮に`input_param=0.0`の場合、初期時刻で取得したセンサ情報のみを用いて動作生成することになる。
    以下は実装例であり、ロボットのカメラ画像と関節角度に対しデータを混合している。

    ```python
    x_image, x_joint = robot.get_sensor_data()

    if loop_ct > 1:
        x_image = x_image * input_param + y_image * (1.0-input_param)
        x_joint = x_joint * input_param + y_joint * (1.0-input_param)

    y_image , y_joint, state = mode(x_image, x_joint, state)
    ```


## Q. 予測画像が異常

1. カメラパラメータを固定する
    学習済みモデルを実ロボットに適用した際、予測画像中に物体が映らない、予測画像がノイジーという問題が発生する。
    カメラパラメータ（例えばホワイトバランスなど）が自動的に変化していることが原因として考えられるため、
    `データ収集時`にカメラパラメータを固定してする。
    もしくは、`データ収集時`と同じような視覚画像になるように、`推論時`にカメラパラメータを調整する。
   

## Q. 対象物に注意が向かない

1. カメラ位置を調整する

    安定した注意点と動作を獲得するために、ロボットの身体（ハンドもしくはアーム）と対象物が、画像中に常に表示されることを推奨する。
    注意点がロボットの身体と対象部に向くことで、両者の時系列関係が学習しやすくなる。
    
2. 対象物を大きくする

    画像中で対象物が占める割合が小さいと、CNNの畳み込みにより物体位置が喪失する可能性がある。
    そのため、対象物を物理的に大きくするか、物体周辺の画像クロップするか、カメラを対象物に近づけること。

3. モデルを再学習する

    モデルの初期重みが原因で対象物に注意が向かない可能性がある。
    同じパラメータで複数回学習を行うことで、5回中3回は対象物に注意が向く結果が得られる。


## Q. データローダをカスタマイズしたい

`MultimodalDataset` クラスを渡すデータの数や、入出力定義を一部変更することで、任意のセンサを追加/削除することが可能である。
以下は、新たにトルクセンサを追加した例を示している。

```python
class MultimodalDataset(Dataset):
    def __init__(self, images, joints, torque, stdev=0.02):
        pass

    def __getitem__(self, idx):
        return [[x_img, x_joint, x_torque], [y_img, y_joint, y_torque]]
```


